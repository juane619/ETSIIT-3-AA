---
title: "P3"
author: "JuanE y Adri"
date: "5 May 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# http://mlbernauer.github.io/R/20150225_coursera_ml_multiclass_classification_logistic_regression.html
# 
# https://github.com/ChicagoBoothML/MachineLearning_Fall2015/blob/master/Programming%20Scripts/Lecture06/mnist_examples.R
```

# 1. AJUSTE DE MODELOS LINEALES

## PROBLEMA DE CLASIFICACIÓN: base de datos "Optical Recognition of Handwritten Digits"

### 1. Comprender el problema a resolver

El problema en si trata de ajustar un modelo lineal sobre dicha base de datos para decidir si un digito es un número entre {0,1,..,9} escritos a mano, es decir, estamos ante un problema de clasificación multi clase (10 clases).
Los conjuntos se generaron dividiendo cada digito en una matriz de 8x8 y calculando un valor de escala de grises de 0 a 16 para cada celda de la matriz promediando sus pixeles. Los datos entonces tienen 64 columnas para cada uno de los valores de escala de grises y una ultima columna (65) con el digito real.

Una manera de resolver este problema podria ser crear 10 clasificadores donde cado uno clasifica entre un digito y los demás y asi con todas las clases. Otra manera podría ser utilizando Softmax, es decir, 

### 2. Preprocesamiento de los datos.

Se leen los datos, dividiendo estos en el conjunto para entrenamiento "train" y en otro conjunto para el test "test".
```{r}
train = read.csv("datos/optdigits_tra.csv", header = FALSE)
names(train)[65] = "digit"
test = read.csv("datos/optdigits_tes.csv", header = FALSE)
names(test)[65] = "digit"

features_train = data.matrix(subset(train, select = -digit))
labels_train   = data.matrix(subset(train, select = digit))
features_test  = data.matrix(subset(test,  select = -digit))
labels_test    = data.matrix(subset(test,  select = digit))
```

Se deben normalizar los datos ya que no es igual considerar los mínimos y máximos globales (dataset completo) que considerar los de cada conjunto, es decir, pudiera ser que se "envenenaran" los conjuntos.

```{r Normalization}

normalized<-function(data) {
  x<-data[!is.na(data)]
  max=max(x)
  min=min(x)
  if(max==min){
      x=0.0
    }
  else
    x<-(x - min(x)) / (max(x) - min(x))
  data[!is.na(data)]<-x
  return(data)
}

features_train = apply(features_train,2,normalized)
features_test = apply(features_test,2,normalized)
```

### 3. Selección de clases de funciones a usar.

Usaremos (ajustaremos) un modelo de regresión LASSO (R-LASSO). Este modelo de regresión lineal selecciona las variables con coeficiente mayor de un umbral prefijado. La ventaja de este modelo es que es una técnica de regresión lineal ya regularizada, es decir, penaliza variables que no dicen nada acerca de la salida, disminuyendo el correspondiente sobreajuste que esto pudiera ocasionar y además reduciendo el error fuera de la muestra.

El hiperparámetro lambda: vamos a estimar el mejor lambda mediante validacion cruzada. El mejor lambda es aquél que penaliza minimizando el error de validacion cruzada, es decir, cvm.

El paquete **glmnet** de R nos permite aplicar todo lo antes mencionado.

**glmnet** es un set de procedimientos extremadamente eficientes para ajustar todo el procedimiento de regularización lasso (también puede hacer elastic-net pero usaremos solo lasso) para regresión lineal, modelos de regresión logística y multinomial (nuestro caso), regresión de Poisson y el modelo de Cox.
Los algoritmos que contiene usan lo que se conoce como descenso cíclico coordinado, que optimiza sucesivamente la función objetivo sobre cada parámetro con otro fijos y cicla hasta que converge.

```{r}
library(glmnet)

#Para parelelizar (demasiado tiempo secuencialmente)
library(doParallel)
registerDoParallel(cores=8)

# Elegimos el mejor lambda por CV de, por ejemplo, 10 particiones (por defecto). Si utilizaramos tantas particiones como numero de muestras que tenemos, estariamos hablando de leave-one-out CV, en este caso no es recomendable por el tamaño del dataset.

cvfit=cv.glmnet(features_train, labels_train, family="multinomial", type.multinomial = "grouped", parallel = TRUE)

best_lambda=cvfit$lambda.min

#Evolucion de los grados de libertad del modelo y porcentaje de desviacion segun los distintos valores de lambda.
plot(cvfit)

plot(cvfit$glmnet.fit, "norm")
abline(h=best_lambda, col= "orange", lty=4, lwd=3)

print ( paste ("El mejor lambda es:", best_lambda))

```

Los anteriores gráficos (uno para cada clase) muestran los valores que toma lambda por cada variable predictora. A nosotros solo nos interesan aquellas que esten por encima de un umbral definido por nosotros. La linea naranja es dicho umbral, el mejor lambda. Las lineas que superan dicho umbral son aquellas variables que son mas significativas para ajustar el modelo.
Cuando la norma L1 (ejeX) es baja, todas las variables nos dicen lo mismo (estimador nulo o aleatorio, es decir, el modelo no sabe nada realmente).

```{r}
#Ajuste del modelo

# El parámetro alpha: cuando el valor es 1 (por defecto) indica Lasso, cuando es 0, indica Ridge.
#En este caso se indica familiy="multinomial" porque estamos ante un problema multiclase.

m_lasso=glmnet(features_train,labels_train, family = "multinomial")

best_lambda=min(m_lasso$lambda)

pred_lasso_train=predict(cvfit, newx = features_train, type= "class", s="lambda.min")

pred_lasso_test=predict(cvfit, newx = features_test, type= "class", s="lambda.min")

#Variables mas significativas
#pred_lasso$`0`>best_lambda

aciertos_train=pred_lasso_train==labels_train
print(sprintf("El procentaje de acierto en train es %s", (length(aciertos_train[aciertos_train==TRUE]) / length(aciertos_train)) * 100))

aciertos_test=pred_lasso_test==labels_test
print(sprintf("El procentaje de acierto en test es %s", (length(aciertos_test[aciertos_test==TRUE]) / length(aciertos_test)) * 100))

```


Explicación de los parámetros de la función cv.glmnet:

lambda -> Son los valores de lambda usados para ajustar
cvm -> La media de los errores de validación cruzada (cross validation measure), es un vector de tamaño length(lambda)
cvsd -> Cross validation standard error de cvm, es la estimación del error estandar de cvm
cvup -> Curva superior que básicamente es cvm+csvd
cvlo -> Curva inferior que es básicamente cvm-csvd
nzero-> Cantidad de coeficientes que nos son cero con cada lambda (VALOR IMPORTANTE)
glmnet.fit -> Un objeto ajustado para todos los datos dados
lambda.min -> Valor del lambda que hace mínimo cvm
lambda.1se -> Mayor valor de lambda tal que el error estandarizado esta dentro de 1


