---
title: "P3"
author: "JuanE y Adri"
date: "5 May 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. AJUSTE DE MODELOS LINEALES

## PROBLEMA DE CLASIFICACIÓN: base de datos "Optical Recognition of Handwritten Digits"

### 1. Comprender el problema a resolver

El problema en si trata de ajustar un modelo lineal sobre dicha base de datos para decidir si un d??gito es un número entre {0,1,..,9} escritos a mano, es decir, estamos ante un problema de clasificación multi clase (10 clases).
Los conjuntos se generaron dividiendo cada d??gito en una matriz de 8x8 y calculando un valor de escala de grises de 0 a 16 para cada celda de la matriz promediando sus p??xeles. Los datos entonces tienen 64 columnas para cada uno de los valores de escala de grises y una ultima columna (65) con el d??gito real.

Una manera de resolver este problema podr??a ser crear 10 clasificadores donde cado uno clasifica entre un d??gito y los demás.

```{r}
train = read.csv("datos/optdigits_tra.csv", header = FALSE)
names(train)[65] = "digit"
test = read.csv("datos/optdigits_tes.csv", header = FALSE)
names(test)[65] = "digit"

features_train = data.matrix(subset(train, select = -digit))
labels_train   = data.matrix(subset(train, select = digit))
features_test  = data.matrix(subset(test,  select = -digit))
labels_test    = data.matrix(subset(test,  select = digit))
```

- Tenemos que encontrar la manera de descubrir que caracter??sticas son importantes pues el dataset básicamente son p??xeles y son muy redundantes (15 16 16 -> Se podr??a resumir en 16)

- Con esto se da la misma prioridad a cada caracter??stica, antes deberiamos de eliminar pixeles redundantes como se ha especificado antes:
```{r Normalization}

normalized<-function(data) {
  x<-data[!is.na(data)]
  max=max(x)
  min=min(x)
  if(max==min){
      x=0.0
    }
  else
    x<-(x - min(x)) / (max(x) - min(x))
  data[!is.na(data)]<-x
  return(data)
}

features_train = apply(features_train,2,normalized)
features_test = apply(features_test,2,normalized)
labels_train= apply(labels_train,2,normalized)
train=as.data.frame(cbind(labels_train, features_train))
train
```

- Con esta función se puede implementar regresión log??stica de manera muy sencilla pero no se si podremos usarla.

- Falta poner la media de comienzo mustart

```{r Logistic Regression}
http://mlbernauer.github.io/R/20150225_coursera_ml_multiclass_classification_logistic_regression.html

Usar softmax o uno contra todos, ajustar el landa en un rango de valores establecido previamente y explicar el porque de esta decisión, una vez tenemos el lambda se lo pasamos a la función de regresión logísitca y explicamos que dicha función regulariza internamente (penaliza caracteristicas)

MIRAR LA DOCUMENTACIÓN DE LA LIBRERIA GLMNET

Preguntar: sin usar glmnet, solo glm, si ajustar uno a uno (cero con todos, sucesivamente) debe de ir bien sin quitar ninguna feature o no??
    usando glmnet (reg logistic con regularization) debemos de ajustar el lambda antes o no??
    hay que hacer uno contra todos 10 veces??
    si hallamos lambda antes(cross validation) y usamos glmnet, debemos de ajustar uno contra todos 10 veces??

library(VGAM)
library(glmnet)

labels_train[,1]=ifelse(labels_train[,1]==0, 0, 1)

m1=glmnet(features_train,labels_train, family = multinomial)

summary(m1)
train=as.data.frame(train)

fit = glmnet(features_train, labels_train, family = "multinomial")
plot(fit, xvar = "dev", label = TRUE)

cvfit=cv.glmnet(features_train, labels_train, family="multinomial", type.multinomial = "grouped", parallel = TRUE)
plot(cvfit)

library(doParallel)
registerDoParallel(cores=8)
warnings()
```
