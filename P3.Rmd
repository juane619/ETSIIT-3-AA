---
title: "P3"
author: "JuanE y Adri"
date: "5 May 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# http://mlbernauer.github.io/R/20150225_coursera_ml_multiclass_classification_logistic_regression.html
# 
# https://github.com/ChicagoBoothML/MachineLearning_Fall2015/blob/master/Programming%20Scripts/Lecture06/mnist_examples.R
```

# 1. AJUSTE DE MODELOS LINEALES

## PROBLEMA DE CLASIFICACIÓN: base de datos "Optical Recognition of Handwritten Digits"

### 1. Comprender el problema a resolver

El problema en si trata de ajustar un modelo lineal sobre dicha base de datos para decidir si un digito es un número entre {0,1,..,9} escritos a mano, es decir, estamos ante un problema de clasificación multi clase (10 clases).
Los conjuntos se generaron dividiendo cada digito en una matriz de 8x8 y calculando un valor de escala de grises de 0 a 16 para cada celda de la matriz promediando sus pixeles. Los datos entonces tienen 64 columnas para cada uno de los valores de escala de grises y una ultima columna (65) con el digito real.

Una manera de resolver este problema podria ser crear 10 clasificadores donde cado uno clasifica entre un digito y los demás y asi con todas las clases. Otra manera podría ser utilizando Softmax, es decir, 

### 2. Preprocesamiento de los datos.

Se leen los datos, dividiendo estos en el conjunto para entrenamiento "train" y en otro conjunto para el test "test".
```{r}
train = read.csv("datos/optdigits_tra.csv", header = FALSE)
names(train)[65] = "digit"
test = read.csv("datos/optdigits_tes.csv", header = FALSE)
names(test)[65] = "digit"

features_train = data.matrix(subset(train, select = -digit))
labels_train   = data.matrix(subset(train, select = digit))
features_test  = data.matrix(subset(test,  select = -digit))
labels_test    = data.matrix(subset(test,  select = digit))
```

Se deben normalizar los datos ya que no es igual considerar los mínimos y máximos globales (dataset completo) que considerar los de cada conjunto, es decir, pudiera ser que se "envenenaran" los conjuntos.

```{r Normalization}

normalized<-function(data) {
  x<-data[!is.na(data)]
  max=max(x)
  min=min(x)
  if(max==min){
      x=0.0
    }
  else
    x<-(x - min(x)) / (max(x) - min(x))
  data[!is.na(data)]<-x
  return(data)
}

features_train = apply(features_train,2,normalized)
features_test = apply(features_test,2,normalized)
```

### 3. Selección de clases de funciones a usar.

Utilizaremos Regresión Logística ya que es un modelo muy usado cuando la respuesta es categórica (exactamente nuestro problema). Como nuestro modelo tiene 10 posibles salidas, nosotros usaremos el tipo de modelo multinomial.

Para este tipo de modelo suponemos que la variable de salida K tiene 10 clases: G={0,1,...,9}.

Una vez conocido nuestro problema y preprocesado los datos, nuestro modelo es el siguiente:

$\mbox{Pr}(G=k|X=x)=\frac{e^{\beta_{0k}+\beta_k^Tx}}{\sum_{\ell=1}^Ke^{\beta_{0\ell}+\beta_\ell^Tx}}$

Como vemos, utiliza la regla Softmax para clasificación multilabel (extension de la clasificacion binaria).

Tenemos la matriz Y NxK, donde $y_{i\ell} = I(g_i=\ell)$, por tanto, la funcion de verosimilitud ya penalizada con LASSO es $\ell(\{\beta_{0k},\beta_{k}\}_1^K) = -\left[\frac{1}{N} \sum_{i=1}^N \Big(\sum_{k=1}^Ky_{il} (\beta_{0k} + x_i^T \beta_k)- \log \big(\sum_{k=1}^K e^{\beta_{0k}+x_i^T \beta_k}\big)\Big)\right] +\lambda \left[ (1-\alpha)||\beta||_F^2/2 + \alpha\sum_{j=1}^p||\beta_j||_q\right]$

Como vemos en dicha funcion, el parametro $\alpha$ define si la penalizacion es LASSO, RIDGE o ambas (elastic-net), nosotros en nuestro problema solo utilizaremos LASSO, es decir, con el parámetro $\alpha=1$, es decir, os quedamos con la parte de $\alpha\sum_{j=1}^p||\beta_j||_q\right]$(lasso) y descartamos la parte $(1-\alpha)||\beta||_F^2/2$ (ridge).

En concreto, usaremos (ajustaremos) un modelo de regresión LASSO (R-LASSO). Este modelo de regresión lineal selecciona las variables con coeficiente mayor de un umbral prefijado. La ventaja de este modelo es que es una técnica de **regresión lineal ya regularizada**, es decir, como los datos de entrada son pixeles, es decir, pueden llegar a ser muy redundantes, dicho modelo ya penaliza variables que no dicen nada acerca de la salida, disminuyendo el correspondiente sobreajuste que esto pudiera ocasionar y además reduciendo el error fuera de la muestra.

El hiperparámetro lambda: vamos a estimar el mejor lambda mediante validacion cruzada. El mejor lambda es aquél que penaliza minimizando el error de validacion cruzada, es decir, cvm.

El paquete **glmnet** de R nos permite aplicar todo lo antes mencionado.

**glmnet** es un set de procedimientos extremadamente eficientes para ajustar todo el procedimiento de regularización lasso (también puede hacer elastic-net pero usaremos solo lasso) para regresión lineal, modelos de regresión logística y multinomial (nuestro caso), regresión de Poisson y el modelo de Cox.
Los algoritmos que contiene usan lo que se conoce como descenso cíclico coordinado, que optimiza sucesivamente la función objetivo sobre cada parámetro con otro fijos y cicla hasta que converge.

```{r}
library(glmnet)

#Para parelelizar (demasiado tiempo secuencialmente)
library(doParallel)
registerDoParallel(cores=8)

# Elegimos el mejor lambda por CV de, por ejemplo, 10 particiones (por defecto). Si utilizaramos tantas particiones como numero de muestras que tenemos, estariamos hablando de leave-one-out CV, en este caso no es recomendable por el tamaño del dataset.

#Ajuste del modelo

cvfit=cv.glmnet(features_train, labels_train, family="multinomial", type.multinomial = "grouped", parallel = TRUE, nfolds = 3)

best_lambda=cvfit$lambda.min

#Evolucion de los grados de libertad del modelo y porcentaje de desviacion segun los distintos valores de lambda.
plot(cvfit)

plot(cvfit$glmnet.fit, "norm")
abline(h=best_lambda, col= "orange", lty=4, lwd=3)

paste ("El mejor lambda es:", best_lambda)

```

Los anteriores gráficos (uno para cada clase) muestran los valores que toma lambda por cada variable predictora. A nosotros solo nos interesan aquellas que esten por encima de un umbral definido por nosotros. La linea naranja es dicho umbral, el mejor lambda. Las lineas que superan dicho umbral son aquellas variables que son mas significativas para ajustar el modelo.
Cuando la norma L1 (ejeX) es baja, todas las variables nos dicen lo mismo (estimador nulo o aleatorio, es decir, el modelo no sabe nada realmente).

```{r}
# Predicciones
pred_lasso_train=predict(cvfit, newx = features_train, type= "class", s="lambda.min")

pred_lasso_test=predict(cvfit, newx = features_test, type= "class", s="lambda.min")

#Variables mas significativas
#cvfit$`1`>best_lambda

aciertos_train=pred_lasso_train==labels_train
sprintf("El error dentro de la muestra (Ein) es %s", (length(aciertos_train[aciertos_train==F]) / length(aciertos_train)) * 100)

aciertos_test=pred_lasso_test==labels_test
sprintf("El error fuera de la muestra (Eout) es %s", (length(aciertos_test[aciertos_test==F]) / length(aciertos_test)) * 100)

```



Explicación de los parámetros de la función cv.glmnet:

lambda -> Son los valores de lambda usados para ajustar
cvm -> La media de los errores de validación cruzada (cross validation measure), es un vector de tamaño length(lambda)
cvsd -> Cross validation standard error de cvm, es la estimación del error estandar de cvm
cvup -> Curva superior que básicamente es cvm+csvd
cvlo -> Curva inferior que es básicamente cvm-csvd
nzero-> Cantidad de coeficientes que nos son cero con cada lambda (VALOR IMPORTANTE)
glmnet.fit -> Un objeto ajustado para todos los datos dados
lambda.min -> Valor del lambda que hace mínimo cvm
lambda.1se -> Mayor valor de lambda tal que el error estandarizado esta dentro de 1


